[
  {
    "objectID": "index.html#about-topfun",
    "href": "index.html#about-topfun",
    "title": "TOPFUN Project Documentation",
    "section": "0.1 About TOPFUN",
    "text": "0.1 About TOPFUN\nTOPFUN is a collaborative project between the Centre for Science, Technology, and Society Studies at Institute of Philosophy of the Czech Academy of Sciences and Equipe de Recherche de Lyon en Sciences de l’Information et de la Communication (ELICO) at Université Claude Bernard Lyon 1."
  },
  {
    "objectID": "index.html#basic-instructions",
    "href": "index.html#basic-instructions",
    "title": "TOPFUN Project Documentation",
    "section": "0.2 Basic instructions",
    "text": "0.2 Basic instructions"
  },
  {
    "objectID": "_main.html#sec-data",
    "href": "_main.html#sec-data",
    "title": "2  Orchestration File",
    "section": "2.1 Data",
    "text": "2.1 Data\nThis section is intended for obtaining data, processing data, and producing topic models. All relevant outputs get exported into their respective pinboards.\nCode in this section needs to be run only by the project administrators.\n\n2.1.1 Get raw data\nHere we obtain data from various sources. Because the sources - APIs, websites, url addresses of files - are external to the project and not persistent, it is unlikely that the code will be reproducible in the longterm. Hence, the main purpose of this section is to document the process of how certain datasets were originally obtained, but it is not expected that researchers will run this code repeatedly.\n\n2.1.1.1 Obtain raw data programatically\nThis sub-section contains functions tailored to specific APIs and websites to be scraped. These might be challenging to run and the execution can take hours or days. As a safeguard against accidental trigger, an evironmental variable has to be explicitly set to execute the code.\n\nSubproject name:\n\ndata_api\n\nRequirements:\n\nSet API_RUN=TRUE in .Renviron to call APIs.\n\n\n\n\nCode\nquarto::quarto_render(\"_data_api.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_api.R\", store = \"_data_api\")\n\n\n\n\n2.1.1.2 Obtain raw data by download\nThe code in this subsection obtains those datasets that need not be collected via APIs or scraping, because they are distributed as files that can be directly downloaded. Setting url addresses for downloads is therefore necessary. Data are simply downloaded and kept as raw data. Processing is documented separarely in Section 2.1.2.\n\nSubproject name:\n\ndata_get\n\nRequirements:\n\nSet URL_CSF=URL in .Renviron.\nSet URL_ANR_2010=URL in .Renviron.\nSet URL_ANR_2009=URL in .Renviron.\nSet URL_CSF=URL in .Renviron.\nSet URL_ANR_2010=URL in .Renviron.\nSet URL_ANR_2010_P=URL in .Renviron.\nSet URL_ANR_2009=URL in .Renviron.\nSet URL_ANR_2009_P=URL in .Renviron.\nSet URL_EU_EUROPE=URL in .Renviron.\nSet URL_EU_2020=URL in .Renviron.\nSet URL_EU_FP7=URL in .Renviron.\nSet URL_SNSF=URL in .Renviron.\n\n\n\n\nCode\nquarto::quarto_render(\"_data_get.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_get.R\", store = \"_data_get\")\n\n\n\n\n\n2.1.2 Process data\n\nSubproject name:\n\ndata_process\n\nRequirements:\n\nSection 2.1.1.2 must be completed.\n\n\nThis code needs to be run only if data sources change and need to be updated. You should only compile this subproject if you know what you are doing and why you are doing it.\n\n\nCode\nquarto::quarto_render(\"_data_process.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_process.R\", store = \"_data_process\")\n\n\n\n\n2.1.3 Build topic model\n\nSubproject name:\n\ndata_topmodel\n\nRequirements:\n\nSection 2.1.2 must be completed.\n\n\n\n\n2.1.4 Export pins\n\nSubproject name:\n\ndata_export\n\nRequirements:\n\nSection 2.1.1.2 must be completed.\nSection 2.1.2 must be completed.\nSection 2.1.3 must be completed.\nSet PINS_BOARD=PATH_TO_PINBOARD in .Renviron.\n\n\nThis code needs to be run only if data sources change and need to be updated. In principle, this is not required except when initializing the project."
  },
  {
    "objectID": "_main.html#sec-analysis",
    "href": "_main.html#sec-analysis",
    "title": "2  Orchestration File",
    "section": "2.2 Analysis (default)",
    "text": "2.2 Analysis (default)\n\nSubproject name:\n\nmain\n\nRequirements:\n\nSee requirements for Section 2.2.1 and Section 2.2.2.\n\n\nThis is the default pipeline. It serves for analysis of the raw data previously exported onto a pinboard.\nCode in this section should be run by all collaborators, on all machines. It is connected to the previous section only by dependency on the generated pins.\n\n2.2.1 (Re)Import pins\nHere we reimport data processed and produced in Section 2.1\n\nSubproject name:\n\ndata_import\n\nRequirements:\n\nSet MANIFEST_URL=URL/_pins.yaml in .Renviron.\ninternet connection.\n\n\n\n\nCode\nquarto::quarto_render(\"_data_import.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_import.R\", store = \"_data_import\")\n\n\n\n\n2.2.2 Analyze data\n\nSubproject name:\n\ndata_analyze\n\nRequirements:\n\nSection 2.2.1 must be completed\n\n\n\n\nCode\nquarto::quarto_render(\"_data_analyze.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_analyze.R\", store = \"_data_analyze\")\n\n\n\n\n2.2.3 Report results\n\n\n2.2.4 Publish docs\n\n\nCode\n#From: https://gist.github.com/cobyism/4730490\nsystem(\"quarto render\")\nsystem(\"touch _book/.nojekyll\")\nsystem(\"git add . && git commit -m 'Update gh-pages'\")\nsystem(\"git subtree push --prefix _book origin gh-pages\")"
  },
  {
    "objectID": "_data_api.html#setup",
    "href": "_data_api.html#setup",
    "title": "3  Obtain raw data programatically",
    "section": "3.1 Setup",
    "text": "3.1 Setup\n\n3.1.1 Set environment for subproject\n\nSys.setenv(TAR_PROJECT = \"data_api\")\n\n\n\n3.1.2 Initialize targets script\n\nlibrary(targets)\ntar_unscript(script = \"_data_api.R\")\nknitr::opts_chunk$set(collapse = TRUE, comment = \"#&gt;\")\n\n\n\n3.1.3 Define targets globals\nWe first define some global options/functions common to all targets.\n\n# read custom functions\nlapply(list.files(here::here(\"R\"), full.names = TRUE), source)\ntar_option_set(packages = packages())\n#&gt; Establish _data_api.R and _data_api_r/globals/globals.R."
  },
  {
    "objectID": "_data_api.html#targets",
    "href": "_data_api.html#targets",
    "title": "3  Obtain raw data programatically",
    "section": "3.2 Targets",
    "text": "3.2 Targets\n\n3.2.1 DFG - Gepris\n\nlist(\n  tar_target(\n    name = dfg_catalogue_tsv,\n    command = scrape_dfg_catalogue(\n      gepris_url = \"https://gepris.dfg.de/gepris/OCTOPUS?beginOfFunding=&bewilligungsStatus=&bundesland=DEU%23&context=projekt&einrichtungsart=-1&fachgebiet=%23&findButton=historyCall&gefoerdertIn=&ggsHunderter=0&hitsPerPage=50&index=1&nurProjekteMitAB=false&oldGgsHunderter=0&oldfachgebiet=%23&pemu=24&peu=%23&task=doKatalog&teilprojekte=true&zk_transferprojekt=false\",\n      outfile = here::here(\"data\", \"data_raw\", \"dfg_catalogue.tsv\"), \n      sleep_time = 5,\n      run = as.logical(Sys.getenv(\"API_RUN\")) #as.logical(Sys.getenv(\"API_RUN\"))\n      ),\n    format = \"file\"\n  ),\ntar_target(\n    name = dfg_projects_tsv,\n    command = scrape_dfg_projects(\n      gepris_catalogue = dfg_catalogue_tsv,\n      outfile = here::here(\"data\", \"data_raw\", \"dfg_projects.tsv\"), \n      sleep_time = 5,\n      run = as.logical(Sys.getenv(\"API_RUN\")) #\n      ),\n    format = \"file\"\n  )\n)\n#&gt; Establish _data_api.R and _data_api_r/targets/dfg.R.\n\n\n\n3.2.2 HAL\n\nlist(\n  tar_target(\n    name = hal_types,\n    command = c(\"ART\", \"COUV\", \"COMM\", \"OUV\")\n  ),\n  tar_target(\n    name = hal_years,\n    command = seq(2008, 2012, 1)\n  ),\n  tar_target(\n    name = hal,\n    command = call_hal(hal_types, hal_years, run = as.logical(Sys.getenv(\"API_RUN\"))),\n    pattern = cross(hal_types, hal_years)\n\n  )\n)\n#&gt; Establish _data_api.R and _data_api_r/targets/hal.R."
  },
  {
    "objectID": "_data_api.html#reset-subproject",
    "href": "_data_api.html#reset-subproject",
    "title": "3  Obtain raw data programatically",
    "section": "3.3 Reset subproject",
    "text": "3.3 Reset subproject\n\nSys.setenv(TAR_PROJECT = \"main\")"
  },
  {
    "objectID": "_data_get.html#setup",
    "href": "_data_get.html#setup",
    "title": "4  Obtain raw data by downloads",
    "section": "4.1 Setup",
    "text": "4.1 Setup\n\n4.1.1 Targets environment for subproject\n\nSys.setenv(TAR_PROJECT = \"data_get\")\n\n\n\n4.1.2 Targets script setup\n\nlibrary(targets)\ntar_unscript(script = \"_data_get.R\")\nknitr::opts_chunk$set(collapse = TRUE, comment = \"#&gt;\")\n\n\n\n4.1.3 Targets globals\nWe first define some global options/functions common to all targets.\n\n# read custom functions\nlapply(list.files(here::here(\"R\"), full.names = TRUE), source)\ntar_option_set(packages = packages())\n# obtain configuration from .Renviron\nurl_csf &lt;- Sys.getenv(\"URL_CSF\")\nurl_anr_2010 &lt;- Sys.getenv(\"URL_ANR_2010\")\nurl_anr_2010_p &lt;- Sys.getenv(\"URL_ANR_2010_P\")\nurl_anr_2009 &lt;- Sys.getenv(\"URL_ANR_2009\")\nurl_anr_2009_p &lt;- Sys.getenv(\"URL_ANR_2009_P\")\nurl_eu_europe  &lt;- Sys.getenv(\"URL_EU_EUROPE\")\nurl_eu_2020 &lt;- Sys.getenv(\"URL_EU_2020\")\nurl_eu_fp7 &lt;- Sys.getenv(\"URL_EU_FP7\")\nurl_snsf &lt;- Sys.getenv(\"URL_SNSF\")\n#&gt; Establish _data_get.R and _data_get_r/globals/globals.R."
  },
  {
    "objectID": "_data_get.html#targets",
    "href": "_data_get.html#targets",
    "title": "4  Obtain raw data by downloads",
    "section": "4.2 Targets",
    "text": "4.2 Targets\n\n4.2.1 Czech Science Foundation\n\nlist(\n  tar_target(\n    name = csf_data_raw,\n    command = readr::read_tsv(url_csf,  show_col_types = FALSE),\n    format = \"qs\"\n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/csf.R.\n\n\n\n4.2.2 Agence nationale de la recherche\n\nlist(\n  tarchetypes::tar_download(\n    name = anr_download_files,\n    urls = c(url_anr_2010, url_anr_2009, url_anr_2010_p, url_anr_2009_p),\n    paths = paste0(\n        here::here(\"data\", \"data_raw\"), \n        .Platform$file.sep,  \n        c(\"anr_2010\", \"anr_2009\", \"anr_2010_p\", \"anr_2009_p\"), \n        \".csv\")\n  ),\n  tar_target(\n    name = anr_data_raw_2010,\n    command = readr::read_delim(anr_download_files[1],\n                                 delim = \";\",\n                                 locale = locale(\"fr\",\n                                                 decimal_mark = \".\"),\n                                                 show_col_types = FALSE) |&gt; \n                                                 janitor::clean_names()|&gt; \n                                                 dplyr::mutate(source = \"since2010\"),\n    format = \"qs\"\n  ),\n  tar_target(\n    name = anr_data_raw_2009,\n    command = readr::read_delim(anr_download_files[2],\n                                 delim = \";\",\n                                 locale = locale(\"fr\",\n                                                 decimal_mark = \".\"),\n                                show_col_types = FALSE) |&gt; \n                                                 janitor::clean_names() |&gt; \n                                                 dplyr::mutate(source = \"before2009\"),\n    format = \"qs\"\n  ),\n  tar_target(\n    name = anr_data_raw,\n    command = dplyr::bind_rows(\n        anr_data_raw_2010,\n        anr_data_raw_2009\n    ),\n    format = \"qs\"\n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/anr.R.\n\n\n\n4.2.3 CORDIS\n\nlist(\n  tarchetypes::tar_download(\n    name = eu_download_files_zip,\n    urls = c(url_eu_europe, url_eu_2020, url_eu_fp7),\n    paths = paste0(\n        here::here(\"data\", \"data_raw\"), \n        .Platform$file.sep,  \n        c(\"eu_europe\", \"eu_horizon\", \"eu_fp7\"), \n        \".zip\"),\n    method = \"curl\",\n    mode = \"wb\"\n  ),\n  tar_target(\n    name = eu_download_files,\n    command = unzip_eu_files(eu_download_files_zip),\n    format = \"file\" \n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/cordis.R.\n\n\n\n4.2.4 Swiss National Science Foundation\n\nlist(\n  tarchetypes::tar_download(\n    name = snsf_download_files,\n    urls = c(url_snsf),\n    paths = paste0(\n        here::here(\"data\", \"data_raw\"), \n        .Platform$file.sep,  \n        c(\"snsf\"), \n        \".csv\"),\n    method = \"curl\",\n    mode = \"w\"\n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/snsf.R."
  },
  {
    "objectID": "_data_get.html#reset-project",
    "href": "_data_get.html#reset-project",
    "title": "4  Obtain raw data by downloads",
    "section": "4.3 Reset project",
    "text": "4.3 Reset project\n\nSys.setenv(TAR_PROJECT = \"main\")"
  },
  {
    "objectID": "_data_process.html#setup",
    "href": "_data_process.html#setup",
    "title": "5  Process raw data",
    "section": "5.1 Setup",
    "text": "5.1 Setup\n\n5.1.1 Set environment for subproject\n\nSys.setenv(TAR_PROJECT = \"data_process\")\n\n\n\n5.1.2 Initialize targets script\n\nlibrary(targets)\ntar_unscript(script = \"_data_process.R\")\nknitr::opts_chunk$set(collapse = TRUE, comment = \"#&gt;\")\n\n\n\n5.1.3 Define targets globals\nWe first define some global options/functions common to all targets.\n\n# read custom functions\nlapply(list.files(here::here(\"R\"), full.names = TRUE), source)\ntar_option_set(packages = packages())\n#&gt; Establish _data_process.R and _data_process_r/globals/globals.R."
  },
  {
    "objectID": "_data_process.html#targets",
    "href": "_data_process.html#targets",
    "title": "5  Process raw data",
    "section": "5.2 Targets",
    "text": "5.2 Targets"
  },
  {
    "objectID": "_data_process.html#reset-subproject",
    "href": "_data_process.html#reset-subproject",
    "title": "5  Process raw data",
    "section": "5.3 Reset subproject",
    "text": "5.3 Reset subproject\n\nSys.setenv(TAR_PROJECT = \"main\")"
  }
]