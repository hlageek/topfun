[
  {
    "objectID": "index.html#about-topfun",
    "href": "index.html#about-topfun",
    "title": "TOPFUN Project Documentation",
    "section": "0.1 About TOPFUN",
    "text": "0.1 About TOPFUN\nTOPFUN is a collaborative project between the Centre for Science, Technology, and Society Studies at Institute of Philosophy of the Czech Academy of Sciences and Equipe de Recherche de Lyon en Sciences de l’Information et de la Communication (ELICO) at Université Claude Bernard Lyon 1."
  },
  {
    "objectID": "index.html#basic-instructions",
    "href": "index.html#basic-instructions",
    "title": "TOPFUN Project Documentation",
    "section": "0.2 Basic instructions",
    "text": "0.2 Basic instructions"
  },
  {
    "objectID": "README.html#instructions",
    "href": "README.html#instructions",
    "title": "2  TOPFUN project",
    "section": "2.1 Instructions",
    "text": "2.1 Instructions\nTo reproduce the project pipeline, run the following:\n\nin Terminal:\n\ngit clone https://github.com/hlageek/funding-topics.git to clone the repository\n\nin R console:\n\nrenv::restore()` to restore the package environment of the project\ntargets::tar_make() to rebuild the targets\n\n\nYou can then load all the built targets into the R environment by running targets::tar_load(everything()), or alternatively load the individual targets with targets::tar_load(NAME_OF_TARGET)."
  },
  {
    "objectID": "README.html#structure-of-the-repository",
    "href": "README.html#structure-of-the-repository",
    "title": "2  TOPFUN project",
    "section": "2.2 Structure of the repository",
    "text": "2.2 Structure of the repository\n/tar_plan.Rmd definition of targets and documentation of the pipeline\n/_targets.Rscript for execution of the pipeline\n/data/data_raw/*data originating outside of the pipeline\n/data/data_derived/*data produced inside the pipeline\n/docs/* documents (typically html output of Rmd files) produced inside the pipeline\n/Rmd/* Rmd notebooks used to generate the content of /docs\n/R/* functions used by the pipeline"
  },
  {
    "objectID": "Scripts/_main.html#sec-data",
    "href": "Scripts/_main.html#sec-data",
    "title": "3  Orchestration File",
    "section": "3.1 Data",
    "text": "3.1 Data\nThis section is intended for obtaining data, processing data, and producing topic models. All relevant outputs get exported into their respective pinboards.\nCode in this section needs to be run only by the project administrators.\n\n3.1.1 Obtain raw data\nHere we obtain data from various sources. Because the sources - APIs, websites, url addresses of files - are external to the project and not persistent, it is unlikely that the code will be reproducible in the longterm. Hence, the main purpose of this section is to document the process of how certain datasets were originally obtained, but it is not expected that researchers will run this code repeatedly.\n\n3.1.1.1 Obtain raw data programatically\n\n\nCode\ndata_get_api_folder &lt;- here::here(\n  \"Scripts\",\n  \"ProcessingScripts\",\n  \"DataCollectionScripts\"\n)\nquarto::quarto_render(here::here(data_get_api_folder, \"_data_api.qmd\"), quiet = TRUE)\ntargets::tar_make(script = here::here(data_get_api_folder, \"_data_api.R\"), store = \"_stores/_data_api\")\n\n\nThis sub-section contains functions tailored to specific APIs and websites to be scraped. These might be challenging to run and the execution can take hours or days. As a safeguard against accidental trigger, an evironmental variable has to be explicitly set to execute the code.\n\nSubproject name:\n\ndata_api\n\nRequirements:\n\nSet API_RUN=TRUE in .Renviron to call APIs.\n\n\n\n\n3.1.1.2 Obtain raw data by download\n\n\nCode\ndata_get_downloads_files &lt;- here::here(\n  \"Scripts\",\n  \"ProcessingScripts\",\n  \"DataCollectionScripts\",\n  c(\"_data_get.qmd\", \"_data_get.R\"))\nquarto::quarto_render(data_get_downloads_files[1], quiet = TRUE)\ntargets::tar_make(script = data_get_downloads_files[2], store = \"_stores/_data_get\")\n\n\nThe code in this subsection obtains those datasets that need not be collected via APIs or scraping, because they are distributed as files that can be directly downloaded. Setting url addresses for downloads is therefore necessary. Data are simply downloaded and kept as raw data. Processing is documented separarely in Section 3.1.2.\n\nSubproject name:\n\ndata_get\n\nRequirements:\n\nSet URL_CSF=URL in .Renviron.\nSet URL_ANR_2010=URL in .Renviron.\nSet URL_ANR_2009=URL in .Renviron.\nSet URL_CSF=URL in .Renviron.\nSet URL_ANR_2010=URL in .Renviron.\nSet URL_ANR_2010_P=URL in .Renviron.\nSet URL_ANR_2009=URL in .Renviron.\nSet URL_ANR_2009_P=URL in .Renviron.\nSet URL_EU_EUROPE=URL in .Renviron.\nSet URL_EU_2020=URL in .Renviron.\nSet URL_EU_FP7=URL in .Renviron.\nSet URL_SNSF=URL in .Renviron.\n\n\n\n\n\n3.1.2 Process data\n\n\nCode\nquarto::quarto_render(\"_data_process.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_process.R\", store = \"_data_process\")\n\n\n\nSubproject name:\n\ndata_process\n\nRequirements:\n\nSection 3.1.1.2 must be completed.\nSection 3.1.1.1 must be completed.\n\n\nThis code needs to be run only if data sources change and need to be updated. You should only compile this subproject if you know what you are doing and why you are doing it.\n\n\n3.1.3 Build topic model\n\nSubproject name:\n\ndata_topmodel\n\nRequirements:\n\nSection 3.1.2 must be completed.\n\n\n\n\n3.1.4 Export pins\n\nSubproject name:\n\ndata_export\n\nRequirements:\n\nSection 3.1.1.2 must be completed.\nSection 3.1.2 must be completed.\nSection 3.1.3 must be completed.\nSet PINS_BOARD=PATH_TO_PINBOARD in .Renviron.\n\n\nThis code needs to be run only if data sources change and need to be updated. In principle, this is not required except when initializing the project."
  },
  {
    "objectID": "Scripts/_main.html#sec-analysis",
    "href": "Scripts/_main.html#sec-analysis",
    "title": "3  Orchestration File",
    "section": "3.2 Analysis (default)",
    "text": "3.2 Analysis (default)\n\nSubproject name:\n\nmain\n\nRequirements:\n\nSee requirements for Section 3.2.1 and Section 3.2.2.\n\n\nThis is the default pipeline. It serves for analysis of the raw data previously exported onto a pinboard.\nCode in this section should be run by all collaborators, on all machines. It is connected to the previous section only by dependency on the generated pins.\n\n3.2.1 (Re)Import pins\n\n\nCode\nquarto::quarto_render(\"_data_import.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_import.R\", store = \"_data_import\")\n\n\nHere we reimport data processed and produced in Section 3.1\n\nSubproject name:\n\ndata_import\n\nRequirements:\n\nSet MANIFEST_URL=URL/_pins.yaml in .Renviron.\ninternet connection.\n\n\n\n\n3.2.2 Analyze data\n\nSubproject name:\n\ndata_analyze\n\nRequirements:\n\nSection 3.2.1 must be completed\n\n\n\n\nCode\nquarto::quarto_render(\"_data_analyze.qmd\", quiet = TRUE)\ntargets::tar_make(script = \"_data_analyze.R\", store = \"_data_analyze\")\n\n\n\n\n3.2.3 Report results\n\n\n3.2.4 Publish docs\n\n\nCode\n#From: https://gist.github.com/cobyism/4730490\nsystem(\"quarto render\")\nsystem(\"touch _book/.nojekyll\")\nsystem(\"git add . && git commit -m 'Update gh-pages'\")\nsystem(\"git subtree push --prefix _book origin gh-pages\")"
  },
  {
    "objectID": "Scripts/ProcessingScripts/DataCollectionScripts/_data_api.html#setup",
    "href": "Scripts/ProcessingScripts/DataCollectionScripts/_data_api.html#setup",
    "title": "4  Obtain raw data programatically",
    "section": "4.1 Setup",
    "text": "4.1 Setup\n\n4.1.1 Set environment for subproject\n\nSys.setenv(TAR_PROJECT = \"data_api\")\n\n\n\n4.1.2 Initialize targets script\n\nlibrary(targets)\ntar_unscript()\nknitr::opts_chunk$set(collapse = TRUE, comment = \"#&gt;\", tar_script = \"_data_api.R\")\n\n\n\n4.1.3 Define targets globals\nWe first define some global options/functions common to all targets.\n\n# read custom functions\nlapply(list.files(here::here(\"R\"), full.names = TRUE), source)\ntar_option_set(packages = packages())\n#&gt; Establish _data_api.R and _data_api_r/globals/globals.R."
  },
  {
    "objectID": "Scripts/ProcessingScripts/DataCollectionScripts/_data_api.html#targets",
    "href": "Scripts/ProcessingScripts/DataCollectionScripts/_data_api.html#targets",
    "title": "4  Obtain raw data programatically",
    "section": "4.2 Targets",
    "text": "4.2 Targets\n\n4.2.1 DFG - Gepris\nGepris information page (https://gepris.dfg.de/gepris/OCTOPUS?task=showMonitor) at scrape time:\nData Monitor Last update: 26.01.2024\nMost recent date of approval: 26.11.2023 All projects decided upon and approved between 1.1.1999 and the specified award letter date can be found in GEPRIS.\nEntries by Type Count Projects with final reports 40901 Projects 142517 Persons 93668 Institutions 43769 Entries by Research Area Count Humanities and Social Sciences Colour index for Humanities and Social Sciences 26304 Life Sciences Colour index for Life Sciences 49480 Natural Sciences Colour index for Natural Sciences 38446 Engineering Sciences Colour index for Engineering Sciences 26304 Infrastructure 317\n\nlist(\n  tar_target(\n    name = dfg_catalogue_tsv,\n    command = scrape_dfg_catalogue(\n      gepris_url = \"https://gepris.dfg.de/gepris/OCTOPUS?beginOfFunding=&bewilligungsStatus=&bundesland=DEU%23&context=projekt&einrichtungsart=-1&fachgebiet=%23&findButton=historyCall&gefoerdertIn=&ggsHunderter=0&hitsPerPage=50&index=1&nurProjekteMitAB=false&oldGgsHunderter=0&oldfachgebiet=%23&pemu=24&peu=%23&task=doKatalog&teilprojekte=true&zk_transferprojekt=false\",\n      outfile = here::here(\"Data\", \"OriginalData\", \"dfg_catalogue.tsv\"), \n      sleep_time = 5,\n      run = as.logical(Sys.getenv(\"API_RUN\")) #as.logical(Sys.getenv(\"API_RUN\"))\n      ),\n    format = \"file\"\n  ),\ntar_target(\n    name = dfg_projects_tsv,\n    command = scrape_dfg_projects(\n      gepris_catalogue = dfg_catalogue_tsv,\n      outfile = here::here(\"Data\", \"OriginalData\", \"dfg_projects.tsv\"), \n      sleep_time = 5,\n      run = as.logical(Sys.getenv(\"API_RUN\")) #\n      ),\n    format = \"file\"\n  )\n)\n#&gt; Establish _data_api.R and _data_api_r/targets/dfg.R.\n\n\n\n4.2.2 HAL\n\nlist(\n  tar_target(\n    name = hal_types,\n    command = c(\"ART\", \"COUV\", \"COMM\", \"OUV\")\n  ),\n  tar_target(\n    name = hal_years,\n    command = seq(2008, 2012, 1)\n  ),\n  tar_target(\n    name = hal,\n    command = call_hal(hal_types, hal_years, run = as.logical(Sys.getenv(\"API_RUN\"))),\n    pattern = cross(hal_types, hal_years)\n\n  )\n)\n#&gt; Establish _data_api.R and _data_api_r/targets/hal.R."
  },
  {
    "objectID": "Scripts/ProcessingScripts/DataCollectionScripts/_data_api.html#reset-subproject",
    "href": "Scripts/ProcessingScripts/DataCollectionScripts/_data_api.html#reset-subproject",
    "title": "4  Obtain raw data programatically",
    "section": "4.3 Reset subproject",
    "text": "4.3 Reset subproject\n\nSys.setenv(TAR_PROJECT = \"main\")"
  },
  {
    "objectID": "Scripts/ProcessingScripts/DataCollectionScripts/_data_get.html#setup",
    "href": "Scripts/ProcessingScripts/DataCollectionScripts/_data_get.html#setup",
    "title": "5  Obtain raw data by downloads",
    "section": "5.1 Setup",
    "text": "5.1 Setup\n\n5.1.1 Targets environment for subproject\n\nSys.setenv(TAR_PROJECT = \"data_get\")\n\n\n\n5.1.2 Targets script setup\n\nlibrary(targets)\ntar_unscript()\nknitr::opts_chunk$set(tar_script = \"_data_get.R\", collapse = TRUE, comment = \"#&gt;\")\n\n\n\n5.1.3 Targets globals\nWe first define some global options/functions common to all targets.\n\n# read custom functions\nlapply(list.files(here::here(\"R\"), full.names = TRUE), source)\ntar_option_set(packages = packages())\n# obtain configuration from .Renviron\nurl_csf &lt;- Sys.getenv(\"URL_CSF\")\nurl_anr_2010 &lt;- Sys.getenv(\"URL_ANR_2010\")\nurl_anr_2010_p &lt;- Sys.getenv(\"URL_ANR_2010_P\")\nurl_anr_2009 &lt;- Sys.getenv(\"URL_ANR_2009\")\nurl_anr_2009_p &lt;- Sys.getenv(\"URL_ANR_2009_P\")\nurl_eu_europe  &lt;- Sys.getenv(\"URL_EU_EUROPE\")\nurl_eu_2020 &lt;- Sys.getenv(\"URL_EU_2020\")\nurl_eu_fp7 &lt;- Sys.getenv(\"URL_EU_FP7\")\nurl_snsf &lt;- Sys.getenv(\"URL_SNSF\")\n#&gt; Establish _data_get.R and _data_get_r/globals/globals.R."
  },
  {
    "objectID": "Scripts/ProcessingScripts/DataCollectionScripts/_data_get.html#targets",
    "href": "Scripts/ProcessingScripts/DataCollectionScripts/_data_get.html#targets",
    "title": "5  Obtain raw data by downloads",
    "section": "5.2 Targets",
    "text": "5.2 Targets\n\n5.2.1 Czech Science Foundation\n\nlist(\n   tarchetypes::tar_download(\n    name = csf_download_files,\n    urls = url_csf,\n    paths = here::here(\"Data\", \"OriginalData\", \"csf.tsv\")\n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/csf.R.\n\n\n\n5.2.2 Agence nationale de la recherche\n\nlist(\n  tarchetypes::tar_download(\n    name = anr_download_files,\n    urls = c(url_anr_2010, url_anr_2009, url_anr_2010_p, url_anr_2009_p),\n    paths = paste0(\n        here::here(\"Data\", \"OriginalData\"), \n        .Platform$file.sep,  \n        c(\"anr_2010\", \"anr_2009\", \"anr_2010_p\", \"anr_2009_p\"), \n        \".csv\")\n  ),\n  tar_target(\n    name = anr_data_raw_2010,\n    command = readr::read_delim(anr_download_files[1],\n                                 delim = \";\",\n                                 locale = locale(\"fr\",\n                                                 decimal_mark = \".\"),\n                                                 show_col_types = FALSE) |&gt; \n                                                 janitor::clean_names()|&gt; \n                                                 dplyr::mutate(source = \"since2010\"),\n    format = \"qs\"\n  ),\n  tar_target(\n    name = anr_data_raw_2009,\n    command = readr::read_delim(anr_download_files[2],\n                                 delim = \";\",\n                                 locale = locale(\"fr\",\n                                                 decimal_mark = \".\"),\n                                show_col_types = FALSE) |&gt; \n                                                 janitor::clean_names() |&gt; \n                                                 dplyr::mutate(source = \"before2009\"),\n    format = \"qs\"\n  ),\n  tar_target(\n    name = anr_data_raw,\n    command = dplyr::bind_rows(\n        anr_data_raw_2010,\n        anr_data_raw_2009\n    ),\n    format = \"qs\"\n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/anr.R.\n\n\n\n5.2.3 CORDIS\n\nlist(\n  tarchetypes::tar_download(\n    name = eu_download_files_zip,\n    urls = c(url_eu_europe, url_eu_2020, url_eu_fp7),\n    paths = paste0(\n        here::here(\"Data\", \"OriginalData\"), \n        .Platform$file.sep,  \n        c(\"eu_europe\", \"eu_horizon\", \"eu_fp7\"), \n        \".zip\"),\n    method = \"curl\",\n    mode = \"wb\"\n  ),\n  tar_target(\n    name = eu_download_files,\n    command = unzip_eu_files(eu_download_files_zip, data_path = here::here(\"Data\", \"OriginalData\")),\n    format = \"file\" \n  ),\ntar_target(\n    name = eu_data_raw,\n    command = purrr::map_df(eu_download_files, read.csv2) |&gt; \n              dplyr::as_tibble(),\n    format = \"qs\" \n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/cordis.R.\n\n\n\n5.2.4 Swiss National Science Foundation\n\nlist(\n  tarchetypes::tar_download(\n    name = snsf_download_files,\n    urls = c(url_snsf),\n    paths = paste0(\n        here::here(\"Data\", \"OriginalData\"), \n        .Platform$file.sep,  \n        c(\"snsf\"), \n        \".csv\"),\n    method = \"curl\",\n    mode = \"w\"\n  ),\ntar_target(\n    name = snsf_data_raw,\n    command = read.csv2(snsf_download_files)|&gt; \n              dplyr::as_tibble(),\n    format = \"qs\" \n  )\n)\n#&gt; Establish _data_get.R and _data_get_r/targets/snsf.R."
  },
  {
    "objectID": "Scripts/ProcessingScripts/DataCollectionScripts/_data_get.html#reset-project",
    "href": "Scripts/ProcessingScripts/DataCollectionScripts/_data_get.html#reset-project",
    "title": "5  Obtain raw data by downloads",
    "section": "5.3 Reset project",
    "text": "5.3 Reset project\n\nSys.setenv(TAR_PROJECT = \"main\")"
  },
  {
    "objectID": "Scripts/ProcessingScripts/_data_process.html#setup",
    "href": "Scripts/ProcessingScripts/_data_process.html#setup",
    "title": "6  Process raw data",
    "section": "6.1 Setup",
    "text": "6.1 Setup\n\n6.1.1 Set environment for subproject\n\nSys.setenv(TAR_PROJECT = \"data_process\")\n\n\n\n6.1.2 Initialize targets script\n\nlibrary(targets)\ntar_unscript(script = \"_data_process.R\")\nknitr::opts_chunk$set(tar_script = \"_data_process.R\", collapse = TRUE, comment = \"#&gt;\")\n\n\n\n6.1.3 Define targets globals\nWe first define some global options/functions common to all targets.\n\n# read custom functions\nlapply(list.files(here::here(\"R\"), full.names = TRUE), source)\ntar_option_set(packages = packages())\n#&gt; Establish _data_process.R and _data_process_r/globals/globals.R."
  },
  {
    "objectID": "Scripts/ProcessingScripts/_data_process.html#targets",
    "href": "Scripts/ProcessingScripts/_data_process.html#targets",
    "title": "6  Process raw data",
    "section": "6.2 Targets",
    "text": "6.2 Targets\nFirst we register raw data files.\n\nlist(\n  tar_target(\n    name = csf_data_raw,\n    command = targets::tar_read(csf_download_files, store = \"_data_get\"),\n    format = \"file\" \n  ),\n  tar_target(\n    name = anr_data_raw,\n    command = targets::tar_read(anr_download_files, store = \"_data_get\"),\n    format = \"file\" \n  ),\n  tar_target(\n    name = snsf_data_raw,\n    command = targets::tar_read(snsf_download_files, store = \"_data_get\"),\n    format = \"file\" \n  ),\n  tar_target(\n    name = eu_data_raw,\n    command = targets::tar_read(eu_download_files, store = \"_data_get\"),\n    format = \"file\" \n  ),\n  tar_target(\n    name = dfg_data_raw,\n    command = targets::tar_read(dfg_projects_tsv, store = \"_data_api\"),\n    format = \"file\" \n  ),\ntar_target(\n    name = topfun_data_archive,\n    command = archive_topfun_data(data_files = list(\n      csf_data_raw,\n      anr_data_raw,\n      eu_data_raw,\n      snsf_data_raw,\n      dfg_data_raw\n    ),\n    archive_file = here::here(\"Data\", \"IntermediateData\", paste0(\"topfun_data_archive-\", format(Sys.time(), \"%Y%m%d%H%M%S\"), \".zip\")\n    )),\n    format = \"file\" \n  )\n)\n#&gt; Establish _data_process.R and _data_process_r/targets/register_data.R."
  },
  {
    "objectID": "Scripts/ProcessingScripts/_data_process.html#reset-subproject",
    "href": "Scripts/ProcessingScripts/_data_process.html#reset-subproject",
    "title": "6  Process raw data",
    "section": "6.3 Reset subproject",
    "text": "6.3 Reset subproject\n\nSys.setenv(TAR_PROJECT = \"main\")"
  }
]